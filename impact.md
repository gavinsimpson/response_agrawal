% Don't be afraid of Open Access
% T. Poisot, K. Ram
% ...

In a recent Letter, @agrawal2014 raises four points for which scientists
should be skeptical of the Open Access (OA) movement, two of which we think
are particularly mis-leading. First, that the impact factor of OA journals
is not higher than the impact factor of non-OA journals. Secondly, that it
is tempting to use a journals impact factor as a proxy for the quality of a
paper, and therefore, high quaility research published in a less prestigious
OA journals runs the risk of being perceived less favorably.

First, the strong distinction beween OA and non OA journals is a false
dichotomy. OA is a mode of diffusion of scientific literature in which the
authors, or its home institution, buys back the rights of an article to the
publisher, so that the article is free to access. Although some journals apply
an OA licences to their entire content, an increasing number of publishers
are adopting *per* article OA options. Even though, the notion that pure-OA
journals have a lower impact is challenged by some. James Pringle of Thomson
ISI (i) recognizes that the relevance of journals when talking about OA is
dubious and (ii) "prospective authors should not fear publishing in these
journals" [http://www.nature.com/nature/focus/accessdebate/19.html]. In
addition, there are numerous studies showing a clear *Open Access citation
advantage* [http://www.istl.org/10-winter/article2.html].

Second, the fact that OA journals carry less prestige is not a problem with
the OA movement. Measures of journal impact are known to be extremely biased
by a few papers concentrating a few citations, and cannot possibly be used
to estimate the quality of a paper, let alone its *likely impact*. Simply
put, the impact factor of a journal is not the expected number of citations
a single paper will receive. If rigor is important to us, then it is not
acceptable to think that a paper is bad because it was published in a less
established journal, or that a paper is good because it was published in a
highly selective journal; the same paper is just as good, and should be just
as impactful, whether published in *PLoS One* or *Nature*. This point strikes
us as a demonstration that the metrics used for evaluations are biased. The
recent years say the development of *article-level* metrics [@Fenner2013],
which provides a way to measure the impact of an article regardless of what
journal it appeared in. We think that rather than pushing against the OA
model, we should have a discussion about how these measures can be used to
objectively evaluate research output.

@agrawal2014 concludes his paper on the need to find *an alternative model
of publishing that suits the primary goals of scientists*. We would like to
make the point that, particularly in ecology and environmental sciences, the
primary goal of research should be to produce fundamental insights that can
be mobilized to solve large scale problems. Making information flow freely
between scientists, policy-makers, and stakeholders is paramount to this
effort. What does not strikes us as a *primary* goal, is the maximization
of self-aggrandizing, not to mention arbitrary, measures of impact.

## Literature Cited

